# ğŸ§  Carelink

<div align="center">

**An offline-first AI-powered memory companion for caregivers supporting individuals with dementia and Alzheimer's**

[![FastAPI](https://img.shields.io/badge/FastAPI-005571?style=flat&logo=fastapi)](https://fastapi.tiangolo.com/)
[![Next.js](https://img.shields.io/badge/Next.js-15.2-black?style=flat&logo=next.js)](https://nextjs.org/)
[![Python](https://img.shields.io/badge/Python-3.8+-blue?style=flat&logo=python)](https://www.python.org/)
[![TypeScript](https://img.shields.io/badge/TypeScript-5.0-blue?style=flat&logo=typescript)](https://www.typescriptlang.org/)
[![License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)

</div>

---

## ğŸ“‹ Table of Contents

- [Overview](#overview)
- [Features](#features)
- [Tech Stack](#tech-stack)
- [Architecture](#architecture)
- [Prerequisites](#prerequisites)
- [Installation](#installation)
- [Usage](#usage)
- [Project Structure](#project-structure)
- [API Documentation](#api-documentation)
- [Development](#development)
- [Roadmap](#roadmap)
- [Contributing](#contributing)
- [License](#license)

---

## ğŸ¯ Overview

Carelink is a privacy-first, offline-capable application designed to assist caregivers in tracking and analyzing interactions with dementia and Alzheimer's patients. By leveraging local speech-to-text processing and AI analysis, Carelink helps caregivers maintain detailed records, identify patterns, and receive insights without compromising patient privacy.

### Why Carelink?

- **ğŸ”’ Privacy-First**: All processing happens locally - no data leaves your device
- **ğŸ“´ Offline-Capable**: Works without internet connectivity
- **ğŸ¤– AI-Powered**: Intelligent analysis of conversations and behavioral patterns
- **ğŸ“Š Pattern Recognition**: Identifies trends in mood, agitation, and cognitive state
- **â±ï¸ Real-Time Transcription**: Instant audio-to-text conversion
- **ğŸ“ Comprehensive Logging**: Detailed session records for healthcare provider review

---

## âœ¨ Features

### Core Functionality
- **Audio Recording & Transcription**: Record caregiver-patient interactions with real-time speech-to-text conversion using whisper.cpp
- **Session Management**: Track different session types (Medication, Conversation, Meals, Activities, Sundowning)
- **AI-Powered Analysis**: Automatic summarization and sentiment analysis using local LLM (Gemma 3n via Ollama)
- **Timeline View**: Visual timeline of all sessions with filtering and search capabilities
- **Mood & Agitation Tracking**: Monitor emotional states and behavioral patterns over time

### Session Types
- **Medication**: Track medication administration and patient responses
- **Conversation**: Record general conversations and cognitive engagement
- **Meals**: Monitor eating habits and mealtime behaviors
- **Activities**: Document daily activities and participation levels
- **Sundowning**: Track late-day confusion and behavioral changes

### Technical Features
- **Offline-First Architecture**: Full functionality without internet connection
- **Local Data Storage**: Encrypted SQLite database for secure data persistence
- **WebM to WAV Conversion**: Automatic audio format conversion using FFmpeg
- **Real-Time Audio Visualization**: Visual feedback during recording
- **Responsive Design**: Works on desktop, tablet, and mobile devices
- **Dark Mode Support**: Eye-friendly interface for extended use

---

## ğŸ› ï¸ Tech Stack

### Backend
- **[FastAPI](https://fastapi.tiangolo.com/)**: Modern Python web framework for building APIs
- **[SQLite](https://www.sqlite.org/)**: Lightweight, serverless database
- **[whisper.cpp](https://github.com/ggerganov/whisper.cpp)**: High-performance speech recognition
- **[FFmpeg](https://ffmpeg.org/)**: Audio/video processing
- **[Ollama](https://ollama.ai/)**: Local LLM server for AI analysis
- **Python 3.8+**: Core backend language

### Frontend
- **[Next.js 15.2](https://nextjs.org/)**: React framework with App Router
- **[React 19](https://react.dev/)**: UI library
- **[TypeScript 5](https://www.typescriptlang.org/)**: Type-safe JavaScript
- **[Tailwind CSS](https://tailwindcss.com/)**: Utility-first CSS framework
- **[shadcn/ui](https://ui.shadcn.com/)**: Accessible component library
- **[Recharts](https://recharts.org/)**: Data visualization
- **[Lucide React](https://lucide.dev/)**: Icon library

### AI & ML
- **whisper.cpp (base.en model)**: Offline speech-to-text transcription
- **Gemma 3n**: Local language model for text analysis and summarization
- **Ollama Runtime**: Manages local AI model execution

---

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        Frontend Layer                        â”‚
â”‚  (Next.js 15 + React 19 + TypeScript + Tailwind CSS)       â”‚
â”‚  - Audio Recording Interface                                 â”‚
â”‚  - Real-time Transcription Display                          â”‚
â”‚  - Session Timeline & Analytics                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚ REST API (HTTP)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                       API Gateway                            â”‚
â”‚                  (FastAPI + CORS Middleware)                 â”‚
â”‚  - Request Routing                                           â”‚
â”‚  - Global Exception Handling                                 â”‚
â”‚  - Health Check Endpoints                                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚                â”‚                â”‚
        â–¼                â–¼                â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Session     â”‚ â”‚  Transcribe  â”‚ â”‚    Summarize       â”‚
â”‚   Routes      â”‚ â”‚   Routes     â”‚ â”‚     Routes         â”‚
â”‚  - Create     â”‚ â”‚  - Audio     â”‚ â”‚  - AI Analysis     â”‚
â”‚  - Update     â”‚ â”‚    Upload    â”‚ â”‚  - Prompt Chains   â”‚
â”‚  - Delete     â”‚ â”‚  - Process   â”‚ â”‚  - Mood Detection  â”‚
â”‚  - List       â”‚ â”‚              â”‚ â”‚                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚                â”‚                   â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚          Processing Layer                    â”‚
        â”‚                                              â”‚
        â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
        â”‚  â”‚   FFmpeg     â”‚      â”‚   whisper.cpp   â”‚ â”‚
        â”‚  â”‚  (WebMâ†’WAV)  â”‚â”€â”€â”€â”€â”€â–¶â”‚  (WAVâ†’Text)     â”‚ â”‚
        â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
        â”‚                                              â”‚
        â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
        â”‚  â”‚         Ollama (Gemma 3n)            â”‚  â”‚
        â”‚  â”‚      (Textâ†’Analysis/Summary)         â”‚  â”‚
        â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚           Data Layer                      â”‚
        â”‚                                           â”‚
        â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
        â”‚  â”‚      SQLite Database                â”‚ â”‚
        â”‚  â”‚  - sessions                         â”‚ â”‚
        â”‚  â”‚  - transcripts                      â”‚ â”‚
        â”‚  â”‚  - summaries                        â”‚ â”‚
        â”‚  â”‚  - audio_chunks                     â”‚ â”‚
        â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
        â”‚                                           â”‚
        â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
        â”‚  â”‚    File Storage (Local)             â”‚ â”‚
        â”‚  â”‚  - Audio Recordings (.wav)          â”‚ â”‚
        â”‚  â”‚  - Session Metadata                 â”‚ â”‚
        â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“‹ Prerequisites

Before installing Carelink, ensure you have the following installed:

### Required
- **Python 3.8+**: [Download](https://www.python.org/downloads/)
- **Node.js 18+**: [Download](https://nodejs.org/)
- **pnpm**: Package manager (`npm install -g pnpm`)
- **CMake**: For building whisper.cpp ([Download](https://cmake.org/download/))
- **FFmpeg**: Audio processing ([Download](https://ffmpeg.org/download.html))
- **Ollama**: Local LLM runtime ([Download](https://ollama.ai/download))

### Platform-Specific
- **macOS**: Install Xcode Command Line Tools (`xcode-select --install`)
- **Linux**: Install build essentials (`sudo apt-get install build-essential`)
- **Windows**: Install Visual Studio Build Tools

---

## ğŸš€ Installation

### 1. Clone the Repository
```bash
git clone https://github.com/yourusername/Carelink.git
cd Carelink
```

### 2. Setup whisper.cpp
```bash
# Clone whisper.cpp
git clone https://github.com/ggerganov/whisper.cpp.git
cd whisper.cpp

# Build whisper.cpp
cmake -B build
cmake --build build -j --config Release

# Download the English model (360MB)
./models/download-ggml-model.sh base.en

cd ..
```

### 3. Setup Backend
```bash
# Create Python virtual environment
python3 -m venv venv

# Activate virtual environment
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install Python dependencies
pip install -r requirements.txt

# Initialize database
cd backend
python -c "import database; database.init_database()"
cd ..
```

### 4. Setup Ollama & AI Models
```bash
# Install Ollama from https://ollama.ai/download

# Pull the Gemma 3n model
ollama pull gemma3n:latest

# Start Ollama service (keep running in separate terminal)
ollama serve
```

### 5. Setup Frontend
```bash
cd frontend

# Install dependencies
pnpm install

cd ..
```

### 6. Configure Environment (Optional)
Create `.env` files if needed:

**Backend `.env`:**
```env
DATABASE_PATH=../db/carelink.db
WHISPER_MODEL_PATH=../whisper.cpp/models/ggml-base.en.bin
WHISPER_BINARY_PATH=../whisper.cpp/build/bin/main
OLLAMA_API_URL=http://localhost:11434
RECORDINGS_PATH=./recordings
```

**Frontend `.env.local`:**
```env
NEXT_PUBLIC_API_URL=http://localhost:8000
```

---

## ğŸ® Usage

### Starting the Application

#### 1. Start Backend Server
```bash
# From project root
python start_carelink.py

# Or manually
cd backend
source ../venv/bin/activate  # On Windows: ..\venv\Scripts\activate
python main.py
```

The backend API will be available at `http://localhost:8000`

#### 2. Start Frontend Development Server
```bash
# In a new terminal
cd frontend
pnpm run dev
```

The frontend will be available at `http://localhost:3000`

#### 3. Ensure Ollama is Running
```bash
# In a separate terminal
ollama serve
```

### Using the Application

1. **Start a New Session**
   - Click "New Session" on the home page
   - Select session type (Medication, Conversation, etc.)
   - Enter session notes if desired

2. **Record Audio**
   - Click the microphone button to start recording
   - Speak clearly during the interaction
   - Click stop when finished

3. **View Transcription**
   - Audio is automatically transcribed using whisper.cpp
   - Transcript appears in real-time

4. **AI Analysis**
   - System automatically analyzes the session
   - View mood, agitation scores, and AI-generated summary
   - Review key events and patterns

5. **Session Timeline**
   - View all past sessions in chronological order
   - Filter by session type
   - Search by keywords
   - Export session data

---

## ğŸ“ Project Structure

```
Carelink/
â”œâ”€â”€ backend/                    # Python FastAPI backend
â”‚   â”œâ”€â”€ routes/                 # API route handlers
â”‚   â”‚   â”œâ”€â”€ session.py         # Session management
â”‚   â”‚   â”œâ”€â”€ transcribe.py      # Audio transcription
â”‚   â”‚   â”œâ”€â”€ summarize.py       # AI analysis
â”‚   â”‚   â”œâ”€â”€ audio.py           # Audio file handling
â”‚   â”‚   â””â”€â”€ *_chain.py         # Session-specific prompt chains
â”‚   â”œâ”€â”€ prompts/               # AI prompt templates
â”‚   â”œâ”€â”€ recordings/            # Audio file storage
â”‚   â”œâ”€â”€ main.py                # FastAPI application entry
â”‚   â”œâ”€â”€ database.py            # Database connection & setup
â”‚   â”œâ”€â”€ models.py              # Pydantic data models
â”‚   â””â”€â”€ crud.py                # Database operations
â”‚
â”œâ”€â”€ frontend/                  # Next.js React frontend
â”‚   â”œâ”€â”€ app/                   # Next.js 15 App Router
â”‚   â”‚   â”œâ”€â”€ page.tsx          # Home page
â”‚   â”‚   â””â”€â”€ layout.tsx        # Root layout
â”‚   â”œâ”€â”€ components/            # React components
â”‚   â”‚   â””â”€â”€ ui/               # shadcn/ui components
â”‚   â”œâ”€â”€ hooks/                # Custom React hooks
â”‚   â”‚   â””â”€â”€ useAudioRecorder.ts
â”‚   â”œâ”€â”€ lib/                  # Utility functions
â”‚   â”œâ”€â”€ carelink-app.tsx      # Main application component
â”‚   â””â”€â”€ package.json          # Frontend dependencies
â”‚
â”œâ”€â”€ db/                       # Database storage
â”‚   â”œâ”€â”€ carelink.db          # SQLite database
â”‚   â””â”€â”€ schema.sql           # Database schema
â”‚
â”œâ”€â”€ whisper.cpp/             # Speech recognition (external)
â”‚   â”œâ”€â”€ models/              # Whisper AI models
â”‚   â””â”€â”€ build/               # Compiled binaries
â”‚
â”œâ”€â”€ requirements.txt         # Python dependencies
â”œâ”€â”€ start_carelink.py       # Application launcher
â”œâ”€â”€ SETUP.md                # Detailed setup guide
â”œâ”€â”€ FUTURE_EXPANSION_ROADMAP.md  # Development roadmap
â””â”€â”€ README.md               # This file
```

---

## ğŸ”Œ API Documentation

### Base URL
```
http://localhost:8000
```

### Core Endpoints

#### Health Check
```http
GET /health
```
Returns API and database health status.

#### Sessions

**Create Session**
```http
POST /api/sessions
Content-Type: application/json

{
  "session_type": "Medication",
  "notes": "Morning medication administration"
}
```

**List Sessions**
```http
GET /api/sessions?limit=50&offset=0
```

**Get Session by ID**
```http
GET /api/sessions/{session_id}
```

**Update Session**
```http
PUT /api/sessions/{session_id}
Content-Type: application/json

{
  "notes": "Updated session notes",
  "end_ts": "2024-10-12T15:30:00"
}
```

**Delete Session**
```http
DELETE /api/sessions/{session_id}
```

#### Audio & Transcription

**Upload Audio**
```http
POST /api/record-audio
Content-Type: multipart/form-data

{
  "audio": <audio_file.webm>,
  "session_id": "uuid",
  "session_type": "Medication"
}
```

**Transcribe Audio**
```http
POST /api/transcribe
Content-Type: multipart/form-data

{
  "audio": <audio_file.wav>,
  "session_id": "uuid"
}
```

#### AI Analysis

**Generate Summary**
```http
POST /api/summarize
Content-Type: application/json

{
  "session_id": "uuid",
  "transcript_text": "Full transcript text here"
}
```

**Medication Analysis**
```http
POST /api/medication-chain
Content-Type: application/json

{
  "transcript_text": "Transcript of medication session"
}
```

### Response Format

**Success Response (200)**
```json
{
  "status": "success",
  "data": { ... }
}
```

**Error Response (4xx/5xx)**
```json
{
  "detail": "Error description",
  "traceback": "Full error trace (development only)"
}
```

---

## ğŸ’» Development

### Running Tests

**Backend Tests**
```bash
cd backend
pytest
```

**Frontend Tests**
```bash
cd frontend
pnpm test
```

### Development Workflow

1. **Backend Development**
   ```bash
   cd backend
   source ../venv/bin/activate
   uvicorn main:app --reload --host 0.0.0.0 --port 8000
   ```

2. **Frontend Development**
   ```bash
   cd frontend
   pnpm run dev
   ```

3. **Type Checking**
   ```bash
   # Frontend TypeScript
   cd frontend
   pnpm run build  # Checks types during build
   ```

### Code Style

**Python (Backend)**
- Follow PEP 8 guidelines
- Use type hints where possible
- Document functions with docstrings

**TypeScript (Frontend)**
- Use ESLint and Prettier configurations
- Follow React best practices
- Use TypeScript strict mode

### Database Management

**View Database**
```bash
sqlite3 db/carelink.db
.tables
.schema sessions
SELECT * FROM sessions LIMIT 10;
```

**Reset Database**
```bash
cd backend
python -c "import database; database.init_database()"
```

---

## ğŸ—ºï¸ Roadmap

### Current Version: 1.0 (MVP)
- âœ… Offline audio recording
- âœ… Local speech-to-text transcription
- âœ… AI-powered session analysis
- âœ… Session timeline and history
- âœ… Multiple session types

### Phase 1: Foundation (Q1 2025)
- [ ] User authentication (Google OAuth, Email/Password)
- [ ] Multi-tenant architecture
- [ ] Progressive Web App (PWA) capabilities
- [ ] Offline sync and data persistence
- [ ] Enhanced security and encryption

### Phase 2: Intelligence & Mobile (Q2-Q3 2025)
- [ ] Real-time transcription with WebSockets
- [ ] Advanced sentiment and emotion analysis
- [ ] React Native mobile apps (iOS/Android)
- [ ] Push notifications for caregivers
- [ ] Healthcare provider dashboard

### Phase 3: Integration (Q4 2025 - Q1 2026)
- [ ] FHIR compliance
- [ ] EHR system integration (Epic, Cerner)
- [ ] Microservices architecture
- [ ] Cloud deployment options
- [ ] Advanced analytics platform

### Phase 4: Enterprise (2026+)
- [ ] Predictive analytics and ML models
- [ ] HIPAA compliance certification
- [ ] Enterprise reporting and dashboards
- [ ] IoT device integration
- [ ] Multi-language support

See [FUTURE_EXPANSION_ROADMAP.md](FUTURE_EXPANSION_ROADMAP.md) for detailed technical roadmap.

---

## ğŸ¤ Contributing

Contributions are welcome! Please follow these guidelines:

1. **Fork the Repository**
   ```bash
   git fork https://github.com/yourusername/Carelink.git
   ```

2. **Create a Feature Branch**
   ```bash
   git checkout -b feature/your-feature-name
   ```

3. **Make Your Changes**
   - Write clean, documented code
   - Add tests for new features
   - Follow existing code style

4. **Commit Your Changes**
   ```bash
   git commit -m "feat: add your feature description"
   ```

5. **Push to Your Fork**
   ```bash
   git push origin feature/your-feature-name
   ```

6. **Open a Pull Request**
   - Provide clear description of changes
   - Reference any related issues
   - Ensure CI checks pass

### Development Guidelines
- Write clear commit messages (follow [Conventional Commits](https://www.conventionalcommits.org/))
- Add tests for new features
- Update documentation as needed
- Ensure code passes linting and type checks

---

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

---

## ğŸ™ Acknowledgments

- **whisper.cpp**: High-performance speech recognition by [Georgi Gerganov](https://github.com/ggerganov)
- **Ollama**: Local LLM runtime for privacy-focused AI
- **shadcn/ui**: Beautiful and accessible component library
- **FastAPI**: Modern Python web framework
- **Next.js**: React framework for production

---

## ğŸ“ Support

For questions, issues, or feedback:

- **Issues**: [GitHub Issues](https://github.com/yourusername/Carelink/issues)
- **Discussions**: [GitHub Discussions](https://github.com/yourusername/Carelink/discussions)
- **Email**: support@carelink.app

---

## âš ï¸ Disclaimer

Carelink is a tool designed to assist caregivers and should not replace professional medical advice, diagnosis, or treatment. Always seek the advice of qualified healthcare providers with any questions regarding medical conditions.

---

<div align="center">

**Built with â¤ï¸ for caregivers supporting individuals with dementia and Alzheimer's**

[â¬† Back to Top](#-carelink)

</div>
